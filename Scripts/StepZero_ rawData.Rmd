---
title: "Step zero: convert raw exported csv files downloaded from the portal to a subject per row dataset"
author: "K L Purves"
date: '`r format(Sys.time(), "%d %B, %Y")`'

output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
    number_sections: false
    highlight: monochrome
    theme: cerulean
code_folding: show

html_notebook:
  theme: cerulean
toc: yes
---

# Important information before you run this script

This step uses the raw data downloaded from the FLARe portal. Both the user and rating data files need to be stored in the same folder on your computer.They should be called *users.csv* and *ratings.csv* respectively. This should not be in any folder that is synchronised with GitHub in order to ensure data security.

The first part of the script will ask you to select the most recent data rating file, and the remainder of the script will use that information to locate the correct files and datasets on your computer.

# Setup
This section will set up your environment ready to begin processing the data.


#### Clear global environment
```{r Clear global environment}
remove(list = ls())
```

#### load libraries 
This code block will check if you have the appropriate libraries installed. If you do not, it will download and install them for you. If you do, it will simply call them into your local library.

```{r Setup, libraries}

if(!require(reshape2)){
  install.packages("reshape2")
  library(reshape2)
}

if(!require(dplyr)){
  install.packages("dplyr")
  library(dplyr)
}

if(!require(tidyr)){
  install.packages("tidyr")
  library(tidyr)
}

```

#### select ratings data, identify file path and file names

This block will ask you to find the *ratings data* on your computer. it will use this information to identify the right path for the user data, and to create a folder to store the processed data. 

```{r get files and paths}

## file picker
filename_ratings <- file.choose()

## get the path to the directory where the raw data is stored
raw_path <- dirname(filename_ratings)

## create the folders for each stage (note, this will do nothing if they already exist)
dir.create(file.path(raw_path, "StageZero_datasets"), showWarnings = FALSE)
dir.create(file.path(raw_path, "StageOne_datasets"), showWarnings = FALSE)
dir.create(file.path(raw_path, "StageTwo_datasets"), showWarnings = FALSE)
dir.create(file.path(raw_path, "Final_datasets"), showWarnings = FALSE)

## create exclusions directory
dir.create(file.path(raw_path, "Exclusions"), showWarnings = FALSE)


```

#### Set up filename and path variables for later

Having this here makes it easier to adjust if you want to change file or folder naming conventions to suit your project

```{r set up path and filenames}

# paths
exclusions_path <- file.path(raw_path, "Exclusions")
output_path <- file.path(raw_path, "StageZero_datasets")

# file names

file_ratings <- "affectiveRatings_stageZero.csv" 
file_acquisition <- "acquisition_stageZero.csv" 
file_generalisation <- "generalisation_stageZero.csv" 
file_extinction <- "extinction_stageZero.csv" 
file_return <- "returnFear_stageZero.csv" 
file_exclusions <- "dataDrivenExclusions_stageZero.csv" 

# users data reference

filename_users <- file.path(raw_path,"users.csv")
  
```


#### read in data

```{r read in raw data}
ratings <- read.table(filename_ratings,header = TRUE, sep=',')
users <- read.table(filename_users,header = TRUE, sep=',')
```


# Basic data cleaning

these steps clean the raw data , dropping data from test experiments and test subjects to retain only participants

## retain VCU experiment in users data
```{r data }
#identify users that were paticipants in the actual experiment data and nly retain these in our users data set
users <- users[(users$experiment_id == 12),] 

## drop all test IDs from this group. use regular expressions, ignoring case. order the file by user id 
users <- users %>%
  filter(!grepl("tes",username,ignore.case =T)) %>%
  arrange(username)

```

### match participants in the rating data
this step uses the user ids from our now filtered user data to get only the rating data we need

```{r retain correct users}
ratings <- ratings[(ratings$user_id %in% users$id_user),]
```


## Rename numbers to correct identifiers for both datasets
 rename phase id columns to correctly identify phases
1 - 4: affective ratings
5: acquisition
6: generalisation
7: extinction
8: return of fear

and stimulus ID columns to correctly identify stimulus
CSa == 1
CSb == 2
 
```{r rename phase id}

ratings <- ratings %>%
  mutate(phase_id = case_when(phase_id == "1" ~ "Affective_familiarity",
                              phase_id == "2" ~ "Affective_valence",
                              phase_id == "3" ~ "Affective_arousal",
                              phase_id == "4" ~ "Affective_fear",
                              phase_id == "5" ~ "Acquisition",
                              phase_id == "6" ~ "Generalisation",
                              phase_id == "7" ~ "Extinction",
                              phase_id == "8" ~ "Return_of_fear",
                              ))
 
ratings <- ratings %>%
  mutate(stimulus_id = case_when(stimulus_id == 1 ~ "CSa",
                          stimulus_id == 2 ~ "CSb"))

users <- users %>%
  mutate(CSpID= case_when(scream_stimulus_id == "1" ~ "CSa",
                          scream_stimulus_id == "2" ~ "CSb"))
```
## detect any epxeriment restarts and create an exclusions database
This stage will find instances where participants left the task at any stage (restarts) and flag these for consideration in the exclusions file

After restart column is identified, this chunk will identify when the restart occurred


```{r identify restart column}
## create a wide data frame showing any restarts per phase
restart <- dcast(ratings,
                 user_id ~
                   phase_id,
                 value.var="detected_restart",
                 fun.aggregate = sum)

## limit it to our participants
restart <- restart[(restart$user_id %in% users$id_user),]

#identify any restarts during affective ratings
restart$restart_affective_ratings <- as.numeric(ifelse((restart$Affective_familiarity > 0) |
                                           (restart$Affective_valence >0) | 
                                           (restart$Affective_arousal >0) | 
                                           (restart$Affective_fear >0),1,0))

 # identify restarts during any phase
restart$restart_acquisition <- as.numeric(ifelse((restart$Acquisition > 0),1,0))
restart$restart_generalisation <- as.numeric(ifelse((restart$Generalisation > 0),1,0))
restart$restart_extinction <- as.numeric(ifelse((restart$Extinction > 0),1,0))
restart$restart_ROF <- as.numeric(ifelse((restart$Return_of_fear > 0),1,0))

```

turn this into the start of our exclusions dataset

```{r restart into exclusions}

exclusions <- restart %>%
  select(user_id, restart_affective_ratings, restart_acquisition,restart_generalisation,restart_extinction,restart_ROF)

```

# Create a dataset with the minimum, maximum and average volume per phase. 

```{r volume dataset creation}
volme <- dcast(ratings,
               user_id ~
                 phase_id,
               value.var="volume",
               fun.aggregate = mean)

volmi <- dcast(ratings,
               user_id ~
                 phase_id,
               value.var="volume",
               fun.aggregate = min)

volma <- dcast(ratings,
               user_id ~
                 phase_id,
               value.var="volume",
               fun.aggregate = max)

volme[volme == '-Inf'] <- NA
volmi[volmi == '-Inf'] <- NA
volma[volma == '-Inf'] <- NA

volme[volme == 'Inf'] <- NA
volmi[volmi == 'Inf'] <- NA
volma[volma == 'Inf'] <- NA

volme[volme == 'NaN'] <- NA
volmi[volmi == 'NaN'] <- NA
volma[volma == 'NaN'] <- NA

```

merge min, max and mean volume datasets and only retain acquisition trials.

```{r merge volume retain acquisition}

# add a suffix to all indicating what metric is being measured (with the exception of user ID)

names(volme)[2:dim(volme)[2]] <- paste0("Mean_volume_",names(volme)[2:dim(volme)[2]])
names(volmi)[2:dim(volmi)[2]] <- paste0("Minimum_volume_",names(volmi)[2:dim(volmi)[2]])
names(volma)[2:dim(volma)[2]] <- paste0("Maximum_volume_",names(volma)[2:dim(volma)[2]])


# merge
volume <- merge(volmi,volma)
volume <- merge(volume,volme)


# select only acquisition trials

volume <- select(volume,contains(c("user_ID","Acquisition")))

```

Identify possible volume related issues to consider exclusions

```{r volume exclusion creation}


volume <- volume %>%
  mutate(Average_volume_acquisition_below_.5 = case_when(Mean_volume_Acquisition < 0.5 ~ 1,
                                              Mean_volume_Acquisition >= 0.5 ~ 0,
                                              TRUE ~ NA_real_),
         Average_volume_acquisition_below_.7 = case_when(Mean_volume_Acquisition < 0.7 ~ 1,
                                              Mean_volume_Acquisition >= 0.7 ~ 0,
                                              TRUE ~ NA_real_),
         Volume_missing_acquisition = case_when(is.na(Mean_volume_Acquisition) ~ 1,
                                              !is.na(Mean_volume_Acquisition)~ 0,
                                              TRUE ~ NA_real_),
         )

```
add these to the exclusions data set

```{r add volume exlcusions to exclusions set}

vol_exclusions <- volume %>%
  select(user_id,Average_volume_acquisition_below_.5, Average_volume_acquisition_below_.7,Volume_missing_acquisition)

exclusions <- merge(exclusions,vol_exclusions)

```

# Reshape affective and expectancy rating data

This stage will begin processing the critical experiment data.

## reshape data from long to wide

this keeps used, and then creates columns named with phase ID (see list in lines 166-170 above), stimulus ID (CSa or CSb, gen a-d) and the trial order, with each cell containing the affective or expectancy rating for that phase, stimulus and trial.

```{r reshape long to wide}

wide <- dcast(ratings, 
              user_id ~
                phase_id + stimulus_id + 
                phase_iteration,
              value.var = "rating",
              fun.aggregate = max)

```

## adjust missing and not seen values
In this dataframe, missing values are currently identified as 0's and missing data is identified as -Inf. 
There should be a column for every possible trial+ stimulus combination. This means that there will be different patterns of missing data depending on which pseudo randomised trial order the participants saw. 

In this section, we make any occasion where a stimulus was seen but not responded to 999, and anything not shown to the participant as NA. In other words, if a participant was in a pseudorandomised trial order which means they did not see shape b in trial 2 during acquisition, the value in that cell position will be NA. If a participant was in a pseudo-randomised trial order which means they DID see shape b in trial 2 during acquisition, but they failed to respond, the value in that cell position will be 999.


```{r adjust missing values}

wide[wide == 0] <- 999
wide[wide == '-Inf'] <- NA

```

## add subject ID, CSpID, and volume onto the main dataset

```{r add all necessary variables to ratings}

# create dataset of additional variables

## get user specific variables
additional_vars <- users %>%
  select(username,id_user,CSpID) %>%
  rename(user_id = id_user)

## get volume specific variables

volumevars <- volume %>%
  select(user_id,Mean_volume_Acquisition,Minimum_volume_Acquisition,Maximum_volume_Acquisition)

# merge onto volume dataset

additional_vars <- left_join(volumevars,additional_vars) %>%
  relocate(username, .before = Mean_volume_Acquisition) %>%
  relocate(CSpID, .after = username)  
  

# merge all together and drop suer id in favour of username, rename username to Subject_ID

final <- left_join(additional_vars,wide) %>%
  select(-user_id) %>%
  rename(Subject_ID = username)

```

Drop those who didnt do the experiment at all (NA for volume variables is the best and easiest indicator)

```{r drop non participants}

# list of names of experiment variables

non_participant_vars <- c("Mean_volume_Acquisition","Minimum_volume_Acquisition","Maximum_volume_Acquisition")

final <- final %>%
  drop_na(all_of(non_participant_vars ))

```

# save phase 0 cleaned datasets

```{r save clean stage zero dataset}

write.csv(final,paste0(output_path,"/stageZero_complete_data.csv"),row.names = FALSE)

```

# clear global environment again to reset
```{r clear environment at end}

remove(list = ls())


```

